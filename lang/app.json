{
  "source": {
    "app-info": "The {} application provides a convenient solution for assigning predefined categories to a given list of short texts. To utilize this functionality, you need to provide two types of inputs in MS Excel (xlsx) format: a list of [id, text] records and a list of [id, category] records.\n\nIn the demo mode, you can explore the application without providing any inputs. A sample dataset is provided, allowing you to experience the classification process firsthand. However, please note that in the current version, the number of records that can be classified is currently limited to {} randomly selected from the full dataset. This limitation is implemented to manage costs effectively.\n\nWith {}, you can streamline the categorization process and effortlessly assign categories to your short texts, simplifying your workflow and saving valuable time. The app can also be used in interactive mode. If you select this mode, you enter one tet into the field 'Text to be classified' and a comma seperated list of categories in the field Categories. This mode is useful to test edge cases.",
    "texts": "Texts to be categorized:",
    "categories": "Categories:",
    "text_to_classify": "Text to be classified",
    "upload-excel-expressions": "Upload Excel file with expressions",
    "upload-excel-categories": "Upload xlsx file with categories",
    "info-label": "Info",
    "language": "Language",
    "classifying": "Classifying...",
    "classify": "Classify",
    "mode": "Mode",
    "mode-options": ["Demo", "File Upload", "Interactive"],
    "classify-success": "Items have been successfully classified",
    "download-csv": "Download CSV",
    "get-request-error": "An error occurred during the GET request: {}",
    "json-parsing-error": "An error occurred while parsing the JSON response: {}",
    "created_by": "App created by",
    "powered_by": "Powered by",
    "text_translation": "Translations by",
    "version": "Version",
    "llm_settings": "LLM Settings",
    "categories_csv": "Categories (comma separated string, example: red, blue, green)",
    "help_temperature": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n We generally recommend altering this or top_p but not both.",
    "help_top_p": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \nWe generally recommend altering this or temperature but not both.",
    "help_max_tokens": "The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context",
    "help_frequency_penalty": "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
    "help_presence_penalty": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics."
  },
  "en": {
    "app-info": "The {} application provides a convenient solution for assigning predefined categories to a given list of short texts. To utilize this functionality, you need to provide two types of inputs in MS Excel (xlsx) format: a list of [id, text] records and a list of [id, category] records.\n\nIn the demo mode, you can explore the application without providing any inputs. A sample dataset is provided, allowing you to experience the classification process firsthand. However, please note that in the current version, the number of records that can be classified is currently limited to {} randomly selected from the full dataset. This limitation is implemented to manage costs effectively.\n\nWith {}, you can streamline the categorization process and effortlessly assign categories to your short texts, simplifying your workflow and saving valuable time. The app can also be used in interactive mode. If you select this mode, you enter one tet into the field 'Text to be classified' and a comma seperated list of categories in the field Categories. This mode is useful to test edge cases.",
    "texts": "Texts to be categorized:",
    "categories": "Categories:",
    "text_to_classify": "Text to be classified",
    "upload-excel-expressions": "Upload Excel file with expressions",
    "upload-excel-categories": "Upload xlsx file with categories",
    "info-label": "Info",
    "language": "Language",
    "classifying": "Classifying...",
    "classify": "Classify",
    "mode": "Mode",
    "mode-options": ["Demo", "File Upload", "Interactive"],
    "classify-success": "Items have been successfully classified",
    "download-csv": "Download CSV",
    "get-request-error": "An error occurred during the GET request: {}",
    "json-parsing-error": "An error occurred while parsing the JSON response: {}",
    "created_by": "App created by",
    "powered_by": "Powered by",
    "text_translation": "Translations by",
    "version": "Version",
    "llm_settings": "LLM Settings",
    "categories_csv": "Categories (comma separated string, example: red, blue, green)",
    "help_temperature": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n We generally recommend altering this or top_p but not both.",
    "help_top_p": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \nWe generally recommend altering this or temperature but not both.",
    "help_max_tokens": "The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context",
    "help_frequency_penalty": "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
    "help_presence_penalty": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics."
  },
  "de": {
    "app-info": "Die {} Anwendung bietet eine bequeme L\u00f6sung zur Zuordnung vordefinierter Kategorien zu einer gegebenen Liste von Kurztexten. Um diese Funktion nutzen zu k\u00f6nnen, m\u00fcssen Sie zwei Arten von Eingaben im MS Excel (xlsx) Format bereitstellen: eine Liste von [id, text] Datens\u00e4tzen und eine Liste von [id, Kategorie] Datens\u00e4tzen.\n\nIm Demo-Modus k\u00f6nnen Sie die Anwendung erkunden, ohne Eingaben bereitzustellen. Ein Beispieldatensatz wird bereitgestellt, damit Sie den Klassifizierungsprozess aus erster Hand erleben k\u00f6nnen. Bitte beachten Sie jedoch, dass in der aktuellen Version die Anzahl der klassifizierbaren Datens\u00e4tze auf {} zuf\u00e4llig aus dem vollst\u00e4ndigen Datensatz ausgew\u00e4hlte Datens\u00e4tze begrenzt ist. Diese Begrenzung dient der effektiven Kostenverwaltung.\n\nMit {} k\u00f6nnen Sie den Kategorisierungsprozess optimieren und Ihren Kurztexten m\u00fchelos Kategorien zuweisen, um Ihren Arbeitsablauf zu vereinfachen und wertvolle Zeit zu sparen. Die App kann auch im interaktiven Modus verwendet werden. Wenn Sie diesen Modus ausw\u00e4hlen, geben Sie einen Text in das Feld 'Zu klassifizierender Text' ein und eine durch Kommas getrennte Liste von Kategorien in das Feld Kategorien. Dieser Modus ist n\u00fctzlich, um Randf\u00e4lle zu testen.",
    "texts": "Texte zur Kategorisierung:",
    "categories": "Kategorien:",
    "text_to_classify": "Text zur Klassifizierung",
    "upload-excel-expressions": "Excel-Datei mit Ausdr\u00fccken hochladen",
    "upload-excel-categories": "xlsx-Datei mit Kategorien hochladen",
    "info-label": "Info",
    "language": "Sprache",
    "classifying": "Klassifizierung...",
    "classify": "Klassifizieren",
    "mode": "Modus",
    "mode-options": ["Demo", "Datei hochladen", "Interaktiv"],
    "classify-success": "Die Elemente wurden erfolgreich klassifiziert",
    "download-csv": "CSV herunterladen",
    "get-request-error": "Bei der GET-Anfrage ist ein Fehler aufgetreten: {}",
    "json-parsing-error": "Beim Parsen der JSON-Antwort ist ein Fehler aufgetreten: {}",
    "created_by": "App erstellt von",
    "powered_by": "Powered by",
    "text_translation": "\u00dcbersetzungen von",
    "version": "Version",
    "llm_settings": "LLM-Einstellungen",
    "categories_csv": "Kategorien (durch Kommas getrennte Zeichenfolge, Beispiel: rot, blau, gr\u00fcn)",
    "help_temperature": "Welche Abtauchtemperatur soll verwendet werden, zwischen 0 und 2. H\u00f6here Werte wie 0,8 machen die Ausgabe zuf\u00e4lliger, w\u00e4hrend niedrigere Werte wie 0,2 sie fokussierter und deterministischer machen.\nWir empfehlen in der Regel, entweder dies oder top_p zu \u00e4ndern, aber nicht beides.",
    "help_top_p": "Eine Alternative zur Abtauchtemperatur, die als Nukleussampling bezeichnet wird, bei der das Modell die Ergebnisse der Tokens mit top_p-Wahrscheinlichkeitsmasse ber\u00fccksichtigt. Eine Zahl von 0,1 bedeutet, dass nur die Tokens, die 10% der Wahrscheinlichkeitsmasse ausmachen, ber\u00fccksichtigt werden.\nWir empfehlen in der Regel, entweder dies oder die Temperatur zu \u00e4ndern, aber nicht beides.",
    "help_max_tokens": "Die maximale Anzahl von Tokens, die in der Chat-Vervollst\u00e4ndigung generiert werden sollen. Die Gesamtl\u00e4nge der Eingabetokens und der generierten Tokens ist durch den Kontext des Modells begrenzt.",
    "help_frequency_penalty": "Zahl zwischen -2,0 und 2,0. Positive Werte bestrafen neue Tokens basierend auf ihrer bisherigen H\u00e4ufigkeit im Text und verringern die Wahrscheinlichkeit des Modells, dieselbe Zeile wortw\u00f6rtlich zu wiederholen.",
    "help_presence_penalty": "Zahl zwischen -2,0 und 2,0. Positive Werte bestrafen neue Tokens basierend darauf, ob sie bisher im Text erscheinen, und erh\u00f6hen die Wahrscheinlichkeit des Modells, \u00fcber neue Themen zu sprechen."
  },
  "fr": {
    "app-info": "L'application {} offre une solution pratique pour attribuer des cat\u00e9gories pr\u00e9d\u00e9finies \u00e0 une liste donn\u00e9e de courts textes. Pour utiliser cette fonctionnalit\u00e9, vous devez fournir deux types d'entr\u00e9es au format MS Excel (xlsx) : une liste d'enregistrements [id, texte] et une liste d'enregistrements [id, cat\u00e9gorie].\n\nEn mode d\u00e9mo, vous pouvez explorer l'application sans fournir d'entr\u00e9es. Un jeu de donn\u00e9es d'exemple est fourni, ce qui vous permet de d\u00e9couvrir le processus de classification de premi\u00e8re main. Cependant, veuillez noter que dans la version actuelle, le nombre d'enregistrements pouvant \u00eatre class\u00e9s est limit\u00e9 \u00e0 {} s\u00e9lectionn\u00e9s au hasard parmi l'ensemble des donn\u00e9es. Cette limitation est mise en place pour g\u00e9rer efficacement les co\u00fbts.\n\nAvec {}, vous pouvez rationaliser le processus de cat\u00e9gorisation et attribuer facilement des cat\u00e9gories \u00e0 vos courts textes, simplifiant ainsi votre flux de travail et vous faisant gagner un temps pr\u00e9cieux. L'application peut \u00e9galement \u00eatre utilis\u00e9e en mode interactif. Si vous s\u00e9lectionnez ce mode, vous entrez un texte dans le champ 'Texte \u00e0 classer' et une liste de cat\u00e9gories s\u00e9par\u00e9es par des virgules dans le champ Cat\u00e9gories. Ce mode est utile pour tester des cas limites.",
    "texts": "Textes \u00e0 cat\u00e9goriser:",
    "categories": "Cat\u00e9gories:",
    "text_to_classify": "Texte \u00e0 classer",
    "upload-excel-expressions": "T\u00e9l\u00e9charger un fichier Excel avec les expressions",
    "upload-excel-categories": "T\u00e9l\u00e9charger un fichier xlsx avec les cat\u00e9gories",
    "info-label": "Info",
    "language": "Langue",
    "classifying": "Classification en cours...",
    "classify": "Classer",
    "mode": "Mode",
    "mode-options": [
      "D\u00e9mo",
      "T\u00e9l\u00e9chargement de fichiers",
      "Interactif"
    ],
    "classify-success": "Les \u00e9l\u00e9ments ont \u00e9t\u00e9 class\u00e9s avec succ\u00e8s",
    "download-csv": "T\u00e9l\u00e9charger CSV",
    "get-request-error": "Une erreur s'est produite lors de la requ\u00eate GET : {}",
    "json-parsing-error": "Une erreur s'est produite lors de l'analyse de la r\u00e9ponse JSON : {}",
    "created_by": "Application cr\u00e9\u00e9e par",
    "powered_by": "Propuls\u00e9 par",
    "text_translation": "Traductions par",
    "version": "Version",
    "llm_settings": "Param\u00e8tres LLM",
    "categories_csv": "Cat\u00e9gories (cha\u00eene s\u00e9par\u00e9e par des virgules, exemple : rouge, bleu, vert)",
    "help_temperature": "Quelle temp\u00e9rature d'\u00e9chantillonnage utiliser, entre 0 et 2. Des valeurs plus \u00e9lev\u00e9es comme 0,8 rendront la sortie plus al\u00e9atoire, tandis que des valeurs plus basses comme 0,2 la rendront plus cibl\u00e9e et d\u00e9terministe.\nNous recommandons g\u00e9n\u00e9ralement de modifier ceci ou top_p mais pas les deux.",
    "help_top_p": "Une alternative \u00e0 l'\u00e9chantillonnage avec temp\u00e9rature, appel\u00e9e \u00e9chantillonnage du noyau, o\u00f9 le mod\u00e8le consid\u00e8re les r\u00e9sultats des jetons avec une masse de probabilit\u00e9 top_p. Ainsi, 0,1 signifie que seuls les jetons constituant les 10% sup\u00e9rieurs de la masse de probabilit\u00e9 sont pris en compte.\nNous recommandons g\u00e9n\u00e9ralement de modifier ceci ou la temp\u00e9rature mais pas les deux.",
    "help_max_tokens": "Le nombre maximum de jetons \u00e0 g\u00e9n\u00e9rer dans l'ach\u00e8vement du chat. La longueur totale des jetons d'entr\u00e9e et des jetons g\u00e9n\u00e9r\u00e9s est limit\u00e9e par le contexte du mod\u00e8le",
    "help_frequency_penalty": "Nombre entre -2,0 et 2,0. Les valeurs positives p\u00e9nalisent les nouveaux jetons en fonction de leur fr\u00e9quence existante dans le texte jusqu'\u00e0 pr\u00e9sent, r\u00e9duisant ainsi la probabilit\u00e9 que le mod\u00e8le r\u00e9p\u00e8te la m\u00eame ligne textuellement.",
    "help_presence_penalty": "Nombre entre -2,0 et 2,0. Les valeurs positives p\u00e9nalisent les nouveaux jetons en fonction de leur pr\u00e9sence dans le texte jusqu'\u00e0 pr\u00e9sent, augmentant ainsi la probabilit\u00e9 que le mod\u00e8le parle de nouveaux sujets."
  },
  "it": {
    "app-info": "L'applicazione {} fornisce una soluzione conveniente per assegnare categorie predefinite a un elenco di brevi testi. Per utilizzare questa funzionalit\u00e0, \u00e8 necessario fornire due tipi di input in formato MS Excel (xlsx): un elenco di record [id, testo] e un elenco di record [id, categoria].\n\nIn modalit\u00e0 demo, \u00e8 possibile esplorare l'applicazione senza fornire alcun input. Viene fornito un set di dati di esempio, che consente di sperimentare il processo di classificazione in prima persona. Tuttavia, si prega di notare che nella versione attuale, il numero di record che possono essere classificati \u00e8 attualmente limitato a {} selezionati casualmente dal set di dati completo. Questa limitazione \u00e8 stata implementata per gestire efficacemente i costi.\n\nCon {}, \u00e8 possibile semplificare il processo di categorizzazione e assegnare facilmente categorie ai propri brevi testi, semplificando il flusso di lavoro e risparmiando tempo prezioso. L'app pu\u00f2 anche essere utilizzata in modalit\u00e0 interattiva. Se si seleziona questa modalit\u00e0, \u00e8 possibile inserire un testo nel campo 'Testo da classificare' e un elenco di categorie separate da virgole nel campo Categorie. Questa modalit\u00e0 \u00e8 utile per testare casi limite.",
    "texts": "Testi da categorizzare:",
    "categories": "Categorie:",
    "text_to_classify": "Testo da classificare",
    "upload-excel-expressions": "Carica file Excel con espressioni",
    "upload-excel-categories": "Carica file xlsx con categorie",
    "info-label": "Informazioni",
    "language": "Lingua",
    "classifying": "Classificazione in corso...",
    "classify": "Classifica",
    "mode": "Modalit\u00e0",
    "mode-options": ["Demo", "Caricamento File", "Interattivo"],
    "classify-success": "Gli elementi sono stati classificati con successo",
    "download-csv": "Scarica CSV",
    "get-request-error": "Si \u00e8 verificato un errore durante la richiesta GET: {}",
    "json-parsing-error": "Si \u00e8 verificato un errore durante l'analisi della risposta JSON: {}",
    "created_by": "App creata da",
    "powered_by": "Powered by",
    "text_translation": "Traduzioni di",
    "version": "Versione",
    "llm_settings": "Impostazioni LLM",
    "categories_csv": "Categorie (string separate da virgole, esempio: rosso, blu, verde)",
    "help_temperature": "Quale temperatura di campionamento utilizzare, compresa tra 0 e 2. Valori pi\u00f9 alti come 0,8 renderanno l'output pi\u00f9 casuale, mentre valori pi\u00f9 bassi come 0,2 lo renderanno pi\u00f9 focalizzato e deterministico.\n In generale, consigliamo di modificare questo o top_p ma non entrambi.",
    "help_top_p": "Un'alternativa al campionamento con temperatura, chiamata campionamento del nucleo, in cui il modello considera i risultati dei token con la massa di probabilit\u00e0 top_p. Quindi 0,1 significa che vengono considerati solo i token che costituiscono il 10% superiore della massa di probabilit\u00e0. \nIn generale, consigliamo di modificare questo o la temperatura ma non entrambi.",
    "help_max_tokens": "Il numero massimo di token da generare nel completamento della chat. La lunghezza totale dei token di input e dei token generati \u00e8 limitata dal contesto del modello",
    "help_frequency_penalty": "Numero compreso tra -2,0 e 2,0. I valori positivi penalizzano i nuovi token in base alla loro frequenza esistente nel testo finora, riducendo la probabilit\u00e0 del modello di ripetere la stessa riga testuale.",
    "help_presence_penalty": "Numero compreso tra -2,0 e 2,0. I valori positivi penalizzano i nuovi token in base alla loro presenza nel testo finora, aumentando la probabilit\u00e0 del modello di parlare di nuovi argomenti."
  }
}
